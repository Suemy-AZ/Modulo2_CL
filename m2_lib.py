# -*- coding: utf-8 -*-
"""M2_Lib.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1dw_0P41cBBEi2Jd9WVXoWOb70r0YfFgS

Librerías
"""

# Commented out IPython magic to ensure Python compatibility.
import seaborn as sns
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import graphviz
from sklearn import tree
from sklearn.model_selection import train_test_split
from sklearn.metrics import r2_score, mean_squared_error, confusion_matrix, accuracy_score, f1_score, mean_absolute_error
# %matplotlib inline

"""# Cargando los datos"""

# Commented out IPython magic to ensure Python compatibility.
#Suemy Aquino Zumaya
#A00828585
#09/2022
#Módulo 2

from google.colab import drive  # importa libreria
drive.mount("/content/gdrive");  # utiliza comando
#!pwd
#put your own path in google drive
# %cd "/content/gdrive/MyDrive/7mo semestre/cvs"
#!ls

# Open the file and create the data frame
df = pd.read_csv('gender_classification_v7.csv')
df.head()

"""Cargamos un data set de diferentes atributos físicos de las personas para predecir si son hombre o mujeres."""

df.info()

"""Vemos que no hay valores nulos, sin embargo, la columna gender no es numérica por lo que la cambiaremos a valores categóricos de 0 y 1 para mejor manejo."""

df[["gender"]]=np.where(df[["gender"]] == "Female", 1,0 )
#Mujer = 1
#Hombre= 0
df.head()

"""# Visualizando los datos

Obtenemos la correlación entre los datos
"""

corr_df=df.corr(method='pearson')

corr_df.style.background_gradient(cmap='coolwarm')

"""Vemos como se relacionan entre sí por medio de gráficas."""

sns.set()

sns.pairplot(df, hue='gender');

sns.scatterplot(x='forehead_width_cm', y ='forehead_height_cm' ,data = df , hue = 'gender')

"""Vemos que los datos poseen correlación con el género en buena manera y que existe cierta tendencia de los datos.

# Implementación de una solución
Implementaremos un Árbol de Decisión que nos indique si se trata de un hombre o una mujer.
"""

#Dividimos entre variables dependientes e independientes
df_x=df.drop(columns="gender")
df_y=df["gender"]

#Seccionamos los datos en entrenamiento, pruebas y validación con una proporción de 70/25/5
x_train, x_test, y_train, y_test = train_test_split(df_x,df_y,train_size=0.7)
x_test, x_val, y_test, y_val = train_test_split(x_test,y_test,train_size=0.833)

#Árbol de desición
myTree = tree.DecisionTreeClassifier(criterion="entropy")
myTree.fit(x_train,y_train)

#tree.plot_tree(myTree)
feature_names=["long_hair","forehead_width","forehead_height","nose_wide","nose_long","lips_thin","distance"]
class_names=["Female","Male"]
myTreeData = tree.export_graphviz(myTree,feature_names=feature_names,
                                  class_names=class_names,
                                  filled=True, proportion=True)
graphData= graphviz.Source(myTreeData)
graphData

"""## Métricas para probar el modelo
Obtendremos algunos coeficientes que nos representarán el desempeño del modelo
"""

print("Datos de entrenamiento")
y_pred =myTree.predict(x_train)
print('Error cuadrático medio : ', mean_squared_error(y_train, y_pred))
print("Puntaje: ",myTree.score(x_train,y_train))
print("r^2: ",r2_score(y_train,y_pred))
print(confusion_matrix(y_train,y_pred),"\n")

print("Datos de prueba")
y_pred =myTree.predict(x_test)
print('Error cuadrático medio : ', mean_squared_error(y_test, y_pred))
print("Puntaje: ",myTree.score(x_test,y_test))
print("r^2: ",r2_score(y_test,y_pred))
print(confusion_matrix(y_test,y_pred))

"""Validación del modelo con pruebas puntuales"""

print("Datos de validación","\n")

x_val.reset_index(inplace=True, drop=True)
y_val.reset_index(inplace=True, drop=True)

predi= [x_val.loc[0]]
print("Probabilidad de predicción",myTree.predict_proba(predi))
print("Predicción: ",myTree.predict(predi))
print("Real :",y_val.loc[0],"\n")


predi= [x_val.loc[50]]
print("Probabilidad de predicción",myTree.predict_proba(predi))
print("Predicción: ",myTree.predict(predi))
print("Real :",y_val.loc[50],"\n")

predi= [x_val.loc[75]]
print("Probabilidad de predicción",myTree.predict_proba(predi))
print("Predicción: ",myTree.predict(predi))
print("Real :",y_val.loc[75],"\n")

predi= [x_val.loc[150]]
print("Probabilidad de predicción",myTree.predict_proba(predi))
print("Predicción: ",myTree.predict(predi))
print("Real :",y_val.loc[150],"\n")

predi= [x_val.loc[200]]
print("Probabilidad de predicción",myTree.predict_proba(predi))
print("Predicción: ",myTree.predict(predi))
print("Real :",y_val.loc[200])

"""Al ser un árbol demasiado grande, reduciremos los nodos que puedan usarse para ver si simplificando el modelo podemos conseguir iguales o mejores resultados

# Reducir nodos de árbol de decisión
"""

#Reducir nodos
myTree2 = tree.DecisionTreeClassifier(criterion="entropy", max_depth=3)
myTree2.fit(x_train,y_train)

myTreeData = tree.export_graphviz(myTree2,feature_names=feature_names,
                                  class_names=class_names,
                                  filled=True, proportion=True)
graphData= graphviz.Source(myTreeData)
graphData

"""## Métricas para probar el modelo
Obtendremos algunos coeficientes que nos representarán el desempeño del modelo
"""

print("Datos de entrenamiento")
y_pred =myTree2.predict(x_train)
print('Error cuadrático medio : ', mean_squared_error(y_train, y_pred))
print("Puntaje: ",myTree2.score(x_train,y_train))
print("r^2: ",r2_score(y_train,y_pred))
print(confusion_matrix(y_train,y_pred),"\n")

print("Datos de prueba")
y_pred =myTree2.predict(x_test)
print('Error cuadrático medio : ', mean_squared_error(y_test, y_pred))
print("Puntaje: ",myTree2.score(x_test,y_test))
print("r^2: ",r2_score(y_test,y_pred))
print(confusion_matrix(y_test,y_pred))

"""Validación del modelo con pruebas puntuales"""

print("Datos de validación","\n")

predi= [x_val.loc[0]]
print("Probabilidad de predicción",myTree2.predict_proba(predi))
print("Predicción: ",myTree2.predict(predi))
print("Real :",y_val.loc[0],"\n")


predi= [x_val.loc[50]]
print("Probabilidad de predicción",myTree2.predict_proba(predi))
print("Predicción: ",myTree2.predict(predi))
print("Real :",y_val.loc[50],"\n")

predi= [x_val.loc[75]]
print("Probabilidad de predicción",myTree2.predict_proba(predi))
print("Predicción: ",myTree2.predict(predi))
print("Real :",y_val.loc[75],"\n")

predi= [x_val.loc[150]]
print("Probabilidad de predicción",myTree2.predict_proba(predi))
print("Predicción: ",myTree2.predict(predi))
print("Real :",y_val.loc[150],"\n")

predi= [x_val.loc[200]]
print("Probabilidad de predicción",myTree2.predict_proba(predi))
print("Predicción: ",myTree2.predict(predi))
print("Real :",y_val.loc[200])

"""# Podar el árbol

El árbol tiene demasidas vertientes por lo que se reducirán también para ver si se puede obtener un resultado igual o mejor con un modelo aún más simplificado.
"""

myTree3= tree.DecisionTreeClassifier(criterion="entropy")
pruning_data = myTree3.cost_complexity_pruning_path(x_train,y_train)
alphaValues = pruning_data.ccp_alphas
impurityValues = pruning_data.impurities

allTrees=[]

for thisAlpha in alphaValues:
  thisTree = tree.DecisionTreeClassifier(criterion="entropy",random_state=0,ccp_alpha=thisAlpha)

  thisTree.fit(x_train,y_train)
  allTrees.append(thisTree)

#Compare performance for eah tree
allTrainScores = []
allTestScores = []

for thisTree  in allTrees :
  allTrainScores.append(thisTree.score(x_train,y_train))
  allTestScores.append(thisTree.score(x_test,y_test))

print(allTrainScores)
print(allTestScores)
plt.scatter(alphaValues[1:70],allTrainScores[1:70])
plt.plot(alphaValues[1:70],allTestScores[1:70])

na=60 #alpha seleccionada para el árbol
finalTreeData=tree.export_graphviz(allTrees[na],feature_names=feature_names,
                                   class_names=class_names,
                                   filled=True, proportion=True)
graphData = graphviz.Source(finalTreeData)
graphData

"""## Métricas para probar el modelo
Obtendremos algunos coeficientes que nos representarán el desempeño del modelo
"""

print("Datos de entrenamiento")
y_pred =allTrees[na].predict(x_train)
print('Error cuadrático medio : ', mean_squared_error(y_train, y_pred))
print("Puntaje: ",allTrees[na].score(x_train,y_train))
print("r^2: ",r2_score(y_train,y_pred))
print(confusion_matrix(y_train,y_pred),"\n")

print("Datos de prueba")
y_pred =allTrees[na].predict(x_test)
print('Error cuadrático medio : ', mean_squared_error(y_test, y_pred))
print("Puntaje: ",allTrees[na].score(x_test,y_test))
print("r^2: ",r2_score(y_test,y_pred))
print(confusion_matrix(y_test,y_pred))

"""Validación del modelo con pruebas puntuales"""

print("Datos de  validación","\n")

predi= [x_val.loc[0]]
print("Probabilidad de predicción",allTrees[na].predict_proba(predi))
print("Predicción: ",allTrees[na].predict(predi))
print("Real :",y_val.loc[0],"\n")


predi= [x_val.loc[50]]
print("Probabilidad de predicción",allTrees[na].predict_proba(predi))
print("Predicción: ",allTrees[na].predict(predi))
print("Real :",y_val.loc[50],"\n")

predi= [x_val.loc[75]]
print("Probabilidad de predicción",allTrees[na].predict_proba(predi))
print("Predicción: ",allTrees[na].predict(predi))
print("Real :",y_val.loc[75],"\n")

predi= [x_val.loc[150]]
print("Probabilidad de predicción",allTrees[na].predict_proba(predi))
print("Predicción: ",allTrees[na].predict(predi))
print("Real :",y_val.loc[150],"\n")

predi= [x_val.loc[200]]
print("Probabilidad de predicción",allTrees[na].predict_proba(predi))
print("Predicción: ",allTrees[na].predict(predi))
print("Real :",y_val.loc[200])

"""# Conclusión
El modelo con mejor ajustes de datos y mejor desempeño de manera simplificada es el árbol obtenido después de la poda de nodos, ya que este demostró tener baja varianza, alto sesgo y tener un ajuste fit con los datos que se estudiaron.
"""